"""
Script principal pour g√©n√©rer les r√©sultats et pr√©parer la soutenance
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from supernutriscore import (
    NutriScore, ElectreTri, AnalyseResultats,
    creer_profils_limites, definir_poids_criteres
)

def main():
    print("=" * 80)
    print("SUPERNUTRISCORE - Analyse compl√®te")
    print("=" * 80)
    print()
    
    # 1. Chargement des donn√©es
    print("üìÇ Chargement de la base de donn√©es...")
    df = pd.read_csv('base_donnees_boissons.csv', encoding='utf-8')
    df.columns = df.columns.str.strip()
    print(f"‚úì {len(df)} produits charg√©s")
    print()
    
    # 2. Statistiques descriptives
    print("üìä Statistiques descriptives de la base de donn√©es")
    print("-" * 80)
    print(f"Nombre total de produits: {len(df)}")
    print(f"\nDistribution des labels Nutri-Score:")
    print(df['Label_Nutriscore'].value_counts().sort_index())
    print(f"\nNombre de cat√©gories: {df['Categorie'].nunique()}")
    print(f"Produits BIO: {(df['Label_Bio'] == 'OUI').sum()} ({(df['Label_Bio'] == 'OUI').sum()/len(df)*100:.1f}%)")
    print()
    
    # 3. V√©rification du calcul Nutri-Score
    print("üßÆ V√©rification du calcul Nutri-Score")
    print("-" * 80)
    
    # Test avec un produit de la base
    produit_test = df.iloc[6]  # Coca Cola
    print(f"Produit test: {produit_test['Nom_Produit']}")
    print(f"Marque: {produit_test['Marque']}")
    
    resultat = NutriScore.calculer_score_nutritionnel(
        produit_test['Energie_kJ'],
        produit_test['Acides_Gras_Satures_g'],
        produit_test['Sucres_g'],
        produit_test['Sodium_mg'],
        produit_test['Proteines_g'],
        produit_test['Fibres_g'],
        produit_test['Fruits_Legumes_Pct']
    )
    
    print(f"\nR√©sultats:")
    print(f"  Score calcul√©: {resultat['score']}")
    print(f"  Label calcul√©: {resultat['label']}")
    print(f"  Score base de donn√©es: {produit_test['Score_Nutriscore']}")
    print(f"  Label base de donn√©es: {produit_test['Label_Nutriscore']}")
    print(f"  ‚úì Concordance: {resultat['label'] == produit_test['Label_Nutriscore']}")
    print()
    
    # 4. Cr√©ation des profils ELECTRE TRI
    print("üìã Cr√©ation des profils limites ELECTRE TRI")
    print("-" * 80)
    profils = creer_profils_limites(df)
    print("Profils cr√©√©s (valeurs pour chaque crit√®re):")
    print(profils)
    print()
    
    # 5. Classification ELECTRE TRI avec Œª=0.6
    print("üî¨ Classification ELECTRE TRI (Œª=0.6)")
    print("-" * 80)
    
    poids = definir_poids_criteres()
    print("Poids des crit√®res:")
    for crit, poids_val in poids.items():
        print(f"  {crit}: {poids_val:.2f}")
    print()
    
    # Proc√©dure pessimiste
    print("Proc√©dure PESSIMISTE:")
    electre_pess = ElectreTri(poids, profils, lambda_seuil=0.6)
    df_pess_06 = electre_pess.classifier_base_donnees(df, 'pessimiste')
    
    print("Distribution des classes:")
    print(df_pess_06['Classe_ELECTRE_Pessimiste'].value_counts().sort_index())
    
    # Matrice de confusion
    df_pess_06['Classe_Clean'] = df_pess_06['Classe_ELECTRE_Pessimiste'].str.replace("'", "")
    matrice_pess_06 = AnalyseResultats.matrice_confusion(
        df_pess_06['Label_Nutriscore'],
        df_pess_06['Classe_Clean']
    )
    
    print("\nMatrice de confusion (Nutri-Score vs ELECTRE TRI Pessimiste):")
    print(matrice_pess_06)
    
    metriques_pess_06 = AnalyseResultats.calculer_metriques(matrice_pess_06)
    print(f"\nAccuracy: {metriques_pess_06['accuracy']:.2%}")
    print()
    
    # Proc√©dure optimiste
    print("Proc√©dure OPTIMISTE:")
    electre_opt = ElectreTri(poids, profils, lambda_seuil=0.6)
    df_opt_06 = electre_opt.classifier_base_donnees(df, 'optimiste')
    
    print("Distribution des classes:")
    print(df_opt_06['Classe_ELECTRE_Optimiste'].value_counts().sort_index())
    
    df_opt_06['Classe_Clean'] = df_opt_06['Classe_ELECTRE_Optimiste'].str.replace("'", "")
    matrice_opt_06 = AnalyseResultats.matrice_confusion(
        df_opt_06['Label_Nutriscore'],
        df_opt_06['Classe_Clean']
    )
    
    print("\nMatrice de confusion (Nutri-Score vs ELECTRE TRI Optimiste):")
    print(matrice_opt_06)
    
    metriques_opt_06 = AnalyseResultats.calculer_metriques(matrice_opt_06)
    print(f"\nAccuracy: {metriques_opt_06['accuracy']:.2%}")
    print()
    
    # 6. Classification ELECTRE TRI avec Œª=0.7
    print("üî¨ Classification ELECTRE TRI (Œª=0.7)")
    print("-" * 80)
    
    # Proc√©dure pessimiste
    print("Proc√©dure PESSIMISTE:")
    electre_pess_07 = ElectreTri(poids, profils, lambda_seuil=0.7)
    df_pess_07 = electre_pess_07.classifier_base_donnees(df, 'pessimiste')
    
    print("Distribution des classes:")
    print(df_pess_07['Classe_ELECTRE_Pessimiste'].value_counts().sort_index())
    
    df_pess_07['Classe_Clean'] = df_pess_07['Classe_ELECTRE_Pessimiste'].str.replace("'", "")
    matrice_pess_07 = AnalyseResultats.matrice_confusion(
        df_pess_07['Label_Nutriscore'],
        df_pess_07['Classe_Clean']
    )
    
    metriques_pess_07 = AnalyseResultats.calculer_metriques(matrice_pess_07)
    print(f"\nAccuracy: {metriques_pess_07['accuracy']:.2%}")
    print()
    
    # Proc√©dure optimiste
    print("Proc√©dure OPTIMISTE:")
    electre_opt_07 = ElectreTri(poids, profils, lambda_seuil=0.7)
    df_opt_07 = electre_opt_07.classifier_base_donnees(df, 'optimiste')
    
    print("Distribution des classes:")
    print(df_opt_07['Classe_ELECTRE_Optimiste'].value_counts().sort_index())
    
    df_opt_07['Classe_Clean'] = df_opt_07['Classe_ELECTRE_Optimiste'].str.replace("'", "")
    matrice_opt_07 = AnalyseResultats.matrice_confusion(
        df_opt_07['Label_Nutriscore'],
        df_opt_07['Classe_Clean']
    )
    
    metriques_opt_07 = AnalyseResultats.calculer_metriques(matrice_opt_07)
    print(f"\nAccuracy: {metriques_opt_07['accuracy']:.2%}")
    print()
    
    # 7. Comparaison des m√©thodes
    print("üìä Comparaison des m√©thodes")
    print("-" * 80)
    
    comparaison = pd.DataFrame({
        'M√©thode': [
            'ELECTRE TRI Pessimiste (Œª=0.6)',
            'ELECTRE TRI Optimiste (Œª=0.6)',
            'ELECTRE TRI Pessimiste (Œª=0.7)',
            'ELECTRE TRI Optimiste (Œª=0.7)'
        ],
        'Accuracy': [
            metriques_pess_06['accuracy'],
            metriques_opt_06['accuracy'],
            metriques_pess_07['accuracy'],
            metriques_opt_07['accuracy']
        ]
    })
    
    print(comparaison.to_string(index=False))
    print()
    
    # 8. Sauvegarde des r√©sultats
    print("üíæ Sauvegarde des r√©sultats")
    print("-" * 80)
    
    # Ajouter toutes les colonnes de classification au DataFrame original
    df_final = df.copy()
    df_final['Classe_ELECTRE_Pessimiste_06'] = df_pess_06['Classe_ELECTRE_Pessimiste']
    df_final['Classe_ELECTRE_Optimiste_06'] = df_opt_06['Classe_ELECTRE_Optimiste']
    df_final['Classe_ELECTRE_Pessimiste_07'] = df_pess_07['Classe_ELECTRE_Pessimiste']
    df_final['Classe_ELECTRE_Optimiste_07'] = df_opt_07['Classe_ELECTRE_Optimiste']
    
    # Sauvegarder
    output_file = 'resultats_complets.xlsx'
    df_final.to_excel(output_file, index=False)
    print(f"‚úì R√©sultats sauvegard√©s dans: {output_file}")
    
    # Sauvegarder les profils
    profils_file = 'profils_limites.csv'
    profils.to_csv(profils_file)
    print(f"‚úì Profils limites sauvegard√©s dans: {profils_file}")
    
    # Sauvegarder les matrices de confusion
    matrices_file = 'matrices_confusion.xlsx'
    with pd.ExcelWriter(matrices_file) as writer:
        matrice_pess_06.to_excel(writer, sheet_name='Pessimiste_06')
        matrice_opt_06.to_excel(writer, sheet_name='Optimiste_06')
        matrice_pess_07.to_excel(writer, sheet_name='Pessimiste_07')
        matrice_opt_07.to_excel(writer, sheet_name='Optimiste_07')
    print(f"‚úì Matrices de confusion sauvegard√©es dans: {matrices_file}")
    
    # Sauvegarder le tableau de comparaison
    comparaison_file = 'comparaison_methodes.csv'
    comparaison.to_csv(comparaison_file, index=False)
    print(f"‚úì Comparaison sauvegard√©e dans: {comparaison_file}")
    print()
    
    # 9. G√©n√©ration de visualisations
    print("üìà G√©n√©ration des visualisations")
    print("-" * 80)
    
    # Figure 1: Distribution des labels Nutri-Score
    fig, ax = plt.subplots(figsize=(10, 6))
    labels_count = df['Label_Nutriscore'].value_counts().sort_index()
    colors = ['#038141', '#85BB2F', '#FECB02', '#EE8100', '#E63E11']
    labels_count.plot(kind='bar', ax=ax, color=colors)
    ax.set_title('Distribution des labels Nutri-Score', fontsize=14, fontweight='bold')
    ax.set_xlabel('Label', fontsize=12)
    ax.set_ylabel('Nombre de produits', fontsize=12)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=0)
    plt.tight_layout()
    plt.savefig('distribution_nutriscore.png', dpi=300, bbox_inches='tight')
    print("‚úì Graphique 1 sauvegard√©: distribution_nutriscore.png")
    plt.close()
    
    # Figure 2: Heatmap matrice de confusion (Pessimiste Œª=0.6)
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(matrice_pess_06, annot=True, fmt='d', cmap='Blues', ax=ax, cbar_kws={'label': 'Nombre de produits'})
    ax.set_title('Matrice de confusion - ELECTRE TRI Pessimiste (Œª=0.6)', fontsize=14, fontweight='bold')
    ax.set_xlabel('ELECTRE TRI', fontsize=12)
    ax.set_ylabel('Nutri-Score', fontsize=12)
    plt.tight_layout()
    plt.savefig('matrice_confusion_pessimiste_06.png', dpi=300, bbox_inches='tight')
    print("‚úì Graphique 2 sauvegard√©: matrice_confusion_pessimiste_06.png")
    plt.close()
    
    # Figure 3: Comparaison des accuracies
    fig, ax = plt.subplots(figsize=(12, 6))
    x = np.arange(len(comparaison))
    bars = ax.bar(x, comparaison['Accuracy'], color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])
    ax.set_ylabel('Accuracy', fontsize=12)
    ax.set_title('Comparaison des m√©thodes ELECTRE TRI', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(comparaison['M√©thode'], rotation=15, ha='right')
    ax.set_ylim(0, 1)
    ax.grid(axis='y', alpha=0.3)
    
    # Ajouter les valeurs sur les barres
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
                f'{comparaison["Accuracy"].iloc[i]:.1%}',
                ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('comparaison_accuracies.png', dpi=300, bbox_inches='tight')
    print("‚úì Graphique 3 sauvegard√©: comparaison_accuracies.png")
    plt.close()
    
    print()
    print("=" * 80)
    print("‚úÖ ANALYSE TERMIN√âE AVEC SUCC√àS")
    print("=" * 80)
    print()
    print("üìÅ Fichiers g√©n√©r√©s:")
    print("  - resultats_complets.xlsx")
    print("  - profils_limites.csv")
    print("  - matrices_confusion.xlsx")
    print("  - comparaison_methodes.csv")
    print("  - distribution_nutriscore.png")
    print("  - matrice_confusion_pessimiste_06.png")
    print("  - comparaison_accuracies.png")
    print()
    print("üöÄ Pour lancer l'interface graphique, ex√©cutez:")
    print("   streamlit run interface_streamlit.py")
    print()

if __name__ == "__main__":
    main()
